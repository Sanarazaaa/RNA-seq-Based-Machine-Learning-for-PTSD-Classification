{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONfwFgnFpXj/+DJ3tApMdn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanarazaaa/RNA-seq-Based-Machine-Learning-for-PTSD-Classification/blob/main/RNA_seq_Based_Machine_Learning_for_PTSD_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Load data\n",
        "# ---------------------------\n",
        "expr_file = \"GSE97356_RawCounts.csv\"   # genes x samples (Case_1 ... Case_N)\n",
        "meta_file = \"metadata.csv\"             # must contain 'Sample Name' and 'ptsd'\n",
        "\n",
        "expr = pd.read_csv(expr_file, index_col=0)\n",
        "meta = pd.read_csv(meta_file)\n",
        "\n",
        "print(f\"Expression shape (genes x samples): {expr.shape}\")\n",
        "print(f\"Metadata shape (rows): {meta.shape}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Align samples by order (robust to name mismatches)\n",
        "# ---------------------------\n",
        "if \"Sample Name\" not in meta.columns or \"ptsd\" not in meta.columns:\n",
        "    print(\"WARNING: 'Sample Name' and/or 'ptsd' missing in metadata; cannot proceed.\")\n",
        "    # Exit gracefully\n",
        "else:\n",
        "    n = min(expr.shape[1], meta.shape[0])\n",
        "    if expr.shape[1] != meta.shape[0]:\n",
        "        print(f\"NOTE: Mismatched counts. Using first {n} samples in both files (order-based alignment).\")\n",
        "    expr = expr.iloc[:, :n].copy()\n",
        "    meta = meta.iloc[:n].copy()\n",
        "\n",
        "    # Replace Case_* with actual sample names (for readability)\n",
        "    expr.columns = meta[\"Sample Name\"].astype(str).values\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3) Clean and map labels\n",
        "    # ---------------------------\n",
        "    labels_raw = meta[\"ptsd\"].astype(str).str.strip().str.title()\n",
        "    # Map Never -> 0 (control), Past/Current -> 1 (PTSD)\n",
        "    label_map = {\"Never\": 0, \"Past\": 1, \"Current\": 1}\n",
        "    y = labels_raw.map(label_map)\n",
        "\n",
        "    # Drop samples with unmapped/missing labels\n",
        "    valid = ~y.isna()\n",
        "    if valid.sum() < 2:\n",
        "        print(\"WARNING: Too few labeled samples after cleaning. Cannot train a classifier.\")\n",
        "    else:\n",
        "        dropped = (~valid).sum()\n",
        "        if dropped > 0:\n",
        "            print(f\"NOTE: Dropping {dropped} samples with missing/unmapped labels.\")\n",
        "        expr = expr.loc[:, valid.values]\n",
        "        y = y[valid].astype(int)\n",
        "\n",
        "        # ---------------------------\n",
        "        # 4) Filter low-expressed genes and log-transform\n",
        "        #    Keep genes with >=10 counts in at least 20% of samples\n",
        "        # ---------------------------\n",
        "        X_counts = expr.copy()\n",
        "        min_samples = max(1, int(0.2 * X_counts.shape[1]))\n",
        "        keep = (X_counts >= 10).sum(axis=1) >= min_samples\n",
        "        kept_genes = int(keep.sum())\n",
        "        if kept_genes == 0:\n",
        "            print(\"WARNING: Low-expression filter removed all genes; skipping filter.\")\n",
        "            X_counts_f = X_counts\n",
        "        else:\n",
        "            print(f\"Kept {kept_genes} genes after low-expression filtering \"\n",
        "                  f\"(>=10 counts in >={min_samples} samples).\")\n",
        "            X_counts_f = X_counts.loc[keep]\n",
        "\n",
        "        # Log2 transform (stabilizes variance)\n",
        "        X_log = np.log2(X_counts_f + 1.0)\n",
        "        X = X_log.T.values  # samples x genes\n",
        "        y = y.values\n",
        "\n",
        "        # ---------------------------\n",
        "        # 5) Train/test split (stratified)\n",
        "        # ---------------------------\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Show class balance\n",
        "        def counts(arr):\n",
        "            # ensure both classes appear in printout\n",
        "            zeros = np.sum(arr == 0)\n",
        "            ones  = np.sum(arr == 1)\n",
        "            return f\"[0: {zeros}, 1: {ones}]\"\n",
        "        print(\"Class distribution (full):\", counts(y))\n",
        "        print(\"Class distribution (train):\", counts(y_train))\n",
        "        print(\"Class distribution (test):\", counts(y_test))\n",
        "\n",
        "        # ---------------------------\n",
        "        # 6) Build pipeline: SelectKBest -> Standardize -> Balanced linear SVM\n",
        "        # ---------------------------\n",
        "        k = min(1000, X.shape[1])  # cap at 1000 features\n",
        "        pipeline = Pipeline([\n",
        "            (\"select\", SelectKBest(score_func=f_classif, k=k)),\n",
        "            (\"scale\", StandardScaler(with_mean=True)),\n",
        "            (\"svm\", SVC(kernel=\"linear\", class_weight=\"balanced\"))\n",
        "        ])\n",
        "\n",
        "        # Hyperparameter grid (only C matters for linear SVM)\n",
        "        param_grid = {\n",
        "            \"svm__C\": [0.01, 0.1, 1, 10]\n",
        "        }\n",
        "\n",
        "        cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        grid = GridSearchCV(\n",
        "            estimator=pipeline,\n",
        "            param_grid=param_grid,\n",
        "            scoring=\"f1\",           # focus on minority-performance\n",
        "            cv=cv_inner,\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # ---------------------------\n",
        "        # 7) Fit and evaluate on holdout test set\n",
        "        # ---------------------------\n",
        "        grid.fit(X_train, y_train)\n",
        "        print(\"Best parameters:\", grid.best_params_)\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "        y_pred = best_model.predict(X_test)\n",
        "\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred, digits=3))\n",
        "\n",
        "        # ---------------------------\n",
        "        # 8) 5-fold CV on the whole dataset using the best pipeline\n",
        "        # ---------------------------\n",
        "        cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        scoring = {\n",
        "            \"accuracy\": \"accuracy\",\n",
        "            \"precision\": \"precision_macro\",\n",
        "            \"recall\": \"recall_macro\",\n",
        "            \"f1\": \"f1_macro\",\n",
        "            \"roc_auc\": \"roc_auc\"\n",
        "        }\n",
        "        try:\n",
        "            cv_results = cross_validate(best_model, X, y, cv=cv_outer, scoring=scoring, n_jobs=-1)\n",
        "            print(\"\\n5-fold cross-validation (using best pipeline):\")\n",
        "            for m in scoring:\n",
        "                vals = cv_results[f\"test_{m}\"]\n",
        "                print(f\"{m}: {vals.mean():.3f} (+/- {vals.std():.3f})\")\n",
        "        except Exception as e:\n",
        "            # Some scorers (e.g., roc_auc) can fail if a fold becomes single-class; fail gracefully.\n",
        "            print(\"\\nCross-validation warning:\", str(e))\n",
        "            print(\"Continuing without CV scores that failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwYrX3_YeEw-",
        "outputId": "ab074397-c93b-4664-a3a0-e1d52ed09487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expression shape (genes x samples): (25830, 324)\n",
            "Metadata shape (rows): (324, 28)\n",
            "Kept 16231 genes after low-expression filtering (>=10 counts in >=64 samples).\n",
            "Class distribution (full): [0: 201, 1: 123]\n",
            "Class distribution (train): [0: 161, 1: 98]\n",
            "Class distribution (test): [0: 40, 1: 25]\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Best parameters: {'svm__C': 0.01}\n",
            "\n",
            "Confusion Matrix:\n",
            "[[24 16]\n",
            " [ 7 18]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.774     0.600     0.676        40\n",
            "           1      0.529     0.720     0.610        25\n",
            "\n",
            "    accuracy                          0.646        65\n",
            "   macro avg      0.652     0.660     0.643        65\n",
            "weighted avg      0.680     0.646     0.651        65\n",
            "\n",
            "\n",
            "5-fold cross-validation (using best pipeline):\n",
            "accuracy: 0.543 (+/- 0.043)\n",
            "precision: 0.527 (+/- 0.048)\n",
            "recall: 0.528 (+/- 0.051)\n",
            "f1: 0.525 (+/- 0.047)\n",
            "roc_auc: 0.550 (+/- 0.085)\n"
          ]
        }
      ]
    }
  ]
}